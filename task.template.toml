# 任务模板示例，具体内容根据情况编写。

# 大模型客户端设置（可选，使用默认值）
[client_settings]
# API基础URL（OpenAI兼容格式，默认：https://api.deepseek.com）
api_base = "https://api.deepseek.com"
# 模型名称（默认：deepseek-reasoner）
model = "deepseek-reasoner"
# 温度参数（0.0-2.0，默认：0.7）
temperature = 0.7
# 请求超时时间（秒，默认：600）
timeout_secs = 600
# 最大重试次数（默认：3）
max_retries = 3
# 最大切片token数（注释以使用默认值，若要填写数值则需查看模型支持的最大上下文，取约 1/3 以免超出）
# 每次请求的最大文本长度（字符数，用于切片，默认：10000）
# deepseek-reasoner 支持最大 32K 上下文
max_chunk_tokens = 10000

# 并发请求数（默认：2），使用命令行选项 --concurrent 以启用并发模式，
# 否则该配置会被忽略
concurrency = 2

[[task]]
source_lang = "english"
# 可用的语言代码列表见 https://stellaris.paradoxwikis.com/Localisation_modding
target_langs = [
    "simp_chinese",
    # ...
]
# glossary 以及 glossary_custom 中的文件名（忽略 json 后缀名）
glossaries = [
    "stellaris",
]
# 源语言文件所在目录，会自动读取 {localisation_dir}/{source_lang} 下的所有 yml 文件，并将其写入
# localisation_dir/{source_lang}/replace 中的同名 yml 文件中（将文件名中的 l_{source_lang} 替换为 l_{target_lang}）
# 需要为绝对路径或相对于 task.toml 的相对路径
localisation_dir = "./tests/localisation"
